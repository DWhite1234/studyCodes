# 1.store as中的输入INPUTFORMAT,输出OUTPUTFORMAT
create...
STORED AS 
  INPUTFORMAT 'com.hadoop.mapred.DeprecatedLzoTextInputFormat'
  OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'

通过show create table testpartition查看建表语句

CREATE TABLE `testpartition`(
  `id` int)
PARTITIONED BY ( 
  `dt` string)
ROW FORMAT SERDE 
  'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe' 
STORED AS 
    INPUTFORMAT  'org.apache.hadoop.mapred.TextInputFormat' 
    OUTPUTFORMAT   'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
LOCATION
  'hdfs://hadoop104:8020/opt/module/hive-3.1.2/warehouse/testpartition'
TBLPROPERTIES (
"  'bucketing_version'='2', "
  'transient_lastDdlTime'='1623314781')

建表语句不指定INPUTFORMAT,默认使用hadoop的TextInputFormat,只能读普通的文件,但是我们的是Lzo压缩文件,所以需要指定INPUTFORMAT方式为DeprecatedLzoTextInputFormat

官网说明:https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LZO

# 2.建表语句不指定location
默认路径为/user下

# 3.lzo压缩导致select * 和count(*)出现的数据条数不一样
select * 得出正常数据
count(*)数据比正常数据多几条
原因:
    select * 不走yarn任务fetch抓取,不会将索引文件和数据文件合并,inputformat使用的是建表时指定的
    count(*)走yarn任务,使用hive的默认inputformat CombineHiveFormat,会把索引文件和数据文件合并,导致数据多出
解决方法:
    设置hive的inputformat属性   
    set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat 

# 4.动态分区需要指定非严格模式
严格模式的动态分区需要至少指定一个静态分区
非严格模式的则不需要指定静态分区
