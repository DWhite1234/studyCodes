项目所需组件：
1.sparkStreaming
2.kafka
3.Mysql
4.Hbase
5.hadoop
6.ES
7.Redis
8.Canal
9.Scala
10.Java
11.SpringBoot

离线需求（T+1）：
				1.处理什么时候的数据：前一天的数据
				2.什么时候处理：晚上12点半开始跑任务，第二天上班前跑完（12点半的时候昨天的数据完全都到，晚上上网的人少）
实时需求（T+0）：
				1.处理什么时候的数据：当天的数据
				2.什么时候处理：立即处理，7*24小时一直跑
架构图一：
	优点：解耦，数据更安全
	缺点：效率低
架构图二：
	优点：效率高（用到的组件少，数据在不同组件之前的传输耗费的时间更少）
	缺点：耦合性高，数据不安全
-------------------------------日活需求------------------------------------
1.数据来源：用户行为数据=》启动日志（kafka：GMALL_STARTUP）
2.具体逻辑：
	去重：批次间去重（利用redis保存每一批处理过后的数据，mid） A
		批次内去重（使用groupByKey对相同mid的数据聚和到一块，然后按照时间戳从小到大排序，取第一条数据）  B
		
方案一: 			A    		B
		200    120 			60	
方案二：			B			A
		200	   140			60
结论：去重能力强的前去重，因此先做批次间去重，再做批次内去重。
3.数据去处：
Hbase：（明细数据）
	优点：因为保存的是明细数据，需求更灵活
	缺点：数据量大，占用磁盘
	组件本身：
		优点：吞吐量大，幂等性=》保证数据不重从而结合前面手动维护偏移量来达到精准一次消费。
		缺点：不便于查询
Mysql：（结果数据）
	优点：数据量少，占用磁盘空间少
	缺点：需求单一
	组件本身：
		优点：查询快，方便，事务
		缺点：如果使用事务，效率低，数据吞吐量小
将数据保存至Redis
1.存什么
mid
2.用类型存
set(幂等性)
3.redisKey怎么设计
"DAU:"+logDate

使用方案三对批次间的数据做去重（每个批次下获取一次连接）所存在的问题：
1.在使用广播变量时，广播的数据量问题
1
100 0000
10000000
2.跨零点问题
2021-7-2 23:59：58 [a,b,c]
2021-7-3 00:00:03之前 [a,b]

2021-7-2 [a,b,c]
2021-7-3 []

去重后的应该是[a,b]
但是因为跨零点问题[]

create table gmall0225_dau
(
              mid varchar,
              uid varchar,
              appid varchar,
              area varchar,
              os varchar,
              ch varchar,
              type varchar,
              vs varchar,
              logDate varchar,
              logHour varchar,
              ts bigint
              CONSTRAINT dau_pk PRIMARY KEY (mid, logDate));

总结：Hbase有幂等性，那么为什么还要在代码中去重，
因为hbase保存的是相同数据的最后一个时间的数据，
我们求日活是以用户第一次登陆为标准，所以还要在代码中去重。



