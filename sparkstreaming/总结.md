# spark-streaming是什么
是流式数据处理方式之一

输入源:kafka,flume,hdfs等
计算方式:spark原语(算子)
输出:hdfs,数据库等


# DStream(离散化流)
在一定时间内的数据组成了一个个RDD  (一批数据),
这些RDD在一个时间长度上组成了一个序列就叫DStream(离散化流)

# spark-streaming架构
1.接受器
2.driver端
3.executor端(算子逻辑)

# 背压机制
通过参数spark.streaming.receiver.maxRate来限制receiver的数接受速率,但是如果数据处理能力大于接受速率就会导致集群的资源利用率降低,所以在spark 1.5只有引入的背压机制,来动态调节receiver的接受速率,通过参数spark.streaming.backpressure.enabled来开启背压机制,默认为false,需要同时配合spark.streaming.receiver.maxRate来完成

# 直接从kafka消费数据
kafka 0-8 :
    1.ReceiverApi
    2.DirectApi

kafka 0-10:
    1.DirectApi  

区别:
    1.ReceiverApi 负责接受数据,然后发送给其他的executor,executor的接受数据速度和计算能力各不相同,无法控制,会导致集群性能利用率不高,只在早期版本中使用    
    2.DirectApi,主动从kafka消费数据,有自身配合背压机制,可以实现动态调节,提高集群性能的利用率  


# 无状态转化操作
1.sparkstreaming原语类似RDD的算子,会将每个DStream的RDD都走该逻辑,功能与RDD算子基本一样,
2.transform 将DStream转换为RDD,使用RDD的算子进行计算    