# 1.分区表加载数据的方式
1.insert
insert into partition_1 values (1,'zz',10,"20210427");
2.hadoop fs -put,差不到数据,因为分区表的分区信息,存在mysql的元数据中,需要手动修改表,添加分区信息
alter table partition_1 add partition (day="20210428");
3.load加载,如果加载的数据没有分区字段,那么全部放在默认分区,如果有分区字段会放入对应的分区
load data local inpath "/opt/module/hive-3.1.2/datas/partition.txt" into table partition_1;

# 2.添加分区
1.单个添加分区
alter table 表名 add partition(day="20210427")
2.多个添加分区
alter table 表名 add partition(day="20210427")partition(day="20210428")

# 3.删除分区,外部表只会删除分区元数据,不会删除hdfs数据文件
alter table 表名 drop partition(day="20210427")

# 4.查看分区信息
show partitions 分区表;

# 5.让分区文件和分区表产生联系的几种方式
1.手动添加分区信息
alter table 表名 add partition(day="20210427",hour="14")
2.load指定静态分区,会自动创建分区
load data local inpath "" to table 表名 partition(day="20210428",hour="14")
3.修复,能够一次构建所有的分区信息
前提是分区表创建的时候声明了分区,如果没有声明分区,没有用
msck repair table 分区表